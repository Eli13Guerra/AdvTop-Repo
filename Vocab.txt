Lecture: March 3rd, 2023

Set Notation: This notation expresses a coordinate (point) as the position within and across the sets of an element in curly brackets {}.
Mapping diagram: This visual representation connects the elements of the image set with the ones in the domain set.
Relations: These are the sets of order pairs.
Dimensionality Reduction: This is to reduce the number of variables to only those relevant to the model.
Discrete: A variable that can't have values between the available outputs.
Continuous: A variable that can take any value within the domain.
Deterministic Model: This model can be explained by assigning a rule to pair the domain and the image (function).
Function: A mathematical model correlating an independent variable with a dependent variable.
Well-behaved function: It is single-valued, continuous, and its derivative is defined and continues in all its domain.
Stochastic: It is a model whose outputs are dependent on a probability distribution and whose results can't be precisely determined.
Linear regression: It is a mathematical model in the form of y=mx+b that best fits a data set.
Non-linear regression: It is a mathematical model that has a different form than y=mx+b and best fits a data set
Data extraction for physical insight: It is to generate a model whose parameters represent physical properties and help to understand physical phenomena
Data extraction to create new data: It is when a model is generated to predict the behavior of a system and draw conclusions/predictions for future events.

Lecture: March 13th, 2023

Generalized function: Functional. The function of functions. 
Distribution Theory: Is to model behavior that classically would not be well-behaved with well-behaved functions
Sample: It is the subset that's being measured 
Population: It is the global set of all the possible outcomes.
Systematic sampling: Is to take samples from an observable in regular intervals
Deterministic system: When the system behaves by a function.
Statistics: It is the discipline that collects and analyzes data to draw conclusions and inferences about the data.
Random sampling: It is when the sampling frequency is not regular or doesn't follow any logical behavior.
Cluster sampling/stratified sampling: It is when the data is divided into different subsets (based on some criteria), and these are randomly selected for sampling.

Lecture: March 15th, 2023

Random variable: Quantity or object that depends on random events.
Probability density function (PDF): It a function that models the relative probability of a random variable.
Univaraite: A function that depends on only a single variable. 
Probability distribution: Is a function that desribes the probability of the outcomes of a variable.
Discrete random variables: Random variables whose outcomes don't have continuity or midpoints between them.
Probability mass function: aka Discrete density function. Is a distribution of the probability of discrete values, therefore this is not continuos either.
Numeric Set: Set composed of discrete numeric values
Subset: A set composed of elements from an equal or larger set.
Mathematical Axioms: Is a statement than accepted to be true and correct. A set of ruler that define a mathematical space.
Cumulative distribution function (cdf): Is a function that adds from left to right the probability of the outcomes of the distribution (from o to 1)
Complementary cumulative distribution functions (ccdf): 1-cdf (from 1 to 0).
Measure theory: The probability of measuring all the events in a probability population is 1.
Mathematical spaces: Set of mathematical elements that obeys an structure mathematical axioms.
Bounds form an interval: Closed take the boundaries and open don't
Sthocastic convergence: The larger the set becomes or the longer it is studied, it will converge into a well define structure o behavior.
Scheffe's theorem: A function that's a sequence of integrable functions than converge will almost certainly converge. If all the elements converge and can be integrated, the sum of all of them is almost centain to converge.

Lecture: March 17th, 2023

Empirical distribution: Distribution of values taken directly from a physical observable.
Theoretical probability distribution function: It's a function that's use to model or understand data based on tunis parameters that can have or not physical meaning.
Maximum likelihood estimation (MLE): Is estimating the value of the parameters in a function given a set of empirical data.
Parameter Space: Is a space composed by all the possible values of a parameter in a mathematical model.
Conditional Probabilities: Are the probabilities of an outcome given than a previous event or outcome has already occured.
Residual: Is the difference between the observable and the model.
Error: The difference between the observable between a sample and the whole population.
Residual sum of squares: The sum of the squares of the residuals. 
Warsserstein distance: Distance function between two probability distributions.
Z-test or Students t-test: Statistical test to determine if two populations are different.
Central Limit Theorem: The mean of set of samples will follow a normal distribution.
Hypothesis test: Decision making test that allows to draw inferences or conclusion for the population parameters from statistical descriptors of samples.
Null hypothesis (Ho): The hypothesis that can be rejected or not (There's no diffences).
Alternative hypothesis (Ha): The hypothesis that isn't rejected (There are differences).
P-Value: Measures the probability of obtaining the observed results assuming the null hypothesis is true.
Parametric models: Model that captures the behavior of a system through a set of finite values.
Parametric statistics: Statistics that describes the probability of a population through the parameters obtained from samples.
Mixture models: Combinations of multiple models that interpret the behavior of a non-common distribution.
Non-parametric models: Statistical models that don't follow a normal distribution and are normally continuos.
Ranked Data: Data whose numerical value gets replaced by their rank (order).
Correlation Methods: Methods that depend on drawing connections and relationships between sets of data.

Lecture: March 20th, 2023

Open set: () Doesn't include the boundaries
Closed set: [] Includes the boundaries
Two-Dimensional coordinate system: Cartesian place (x,y).
Topological Space: Spaced defined by closeness and neighborhoods of data.
Distance: In a metric space is what defines the comparison rule between elements.
Connectedness: Is how a through how many neighbors are two elements connected of close to each other.
Compactness: How tightly close are the elements from the set to each other.
Continuity: When all the elements in a set have an image.
Cover: A group of sets that collectively contain X as a subset.
Surjective: All elements are mapped.
Non-surjective: Not all elements are mapped.
Injective function: Elements of A map only one element of B, and the elements in B are mapped only once.
Non-injective function: Elements of A map only one element of B, and the elements in B can be mapped more than once.
Convergence: When as a function grows it approaches a finite value.
Vector space: A space form by algebraic operators than can be modified by constants that scale their magnitude.
Corpus: Collection/array.
Linear Algebra: Vector and Matrixes that map a space.

Lecture: March 24th, 2023 (HW3)

Cartesian product: Is the set that contains all the posible ordered combinations consisting of one member from each of the progenitor sets.
Norm: Is the function that gives the total distance (dimension) from the origin to a vector
Dot product: Is the projection of a vector "a" onto a vector "b". Defined as (a*b)=||b||*||a||cos(theta)
Cross product: Is the vector resulting of the operation |A||B|*sin(theta) that's perpendicular to the progenitor vectors.
Projection: Is the respresentation of the magnitud at which a vector has properties like the vector onto which is being projected.
Linear Transformation: Is a function that takes elements from one vector space to another, and complies with the set rules of each vector spaces.
Write a system of linear equations as a matrix:
4x * 5y = a    [ 4;5.    [x.    =.   [a
6x * 7y = b.     6;7]     y].         b]
Identity matrix (+uses): Is the standard basis of a vector space. Any vector can be expresses as a linear combination of it. It is used for eigendecomposition.
Determinant: Is a scalar that represents a property of the matrix.
Canonical form of a matrix: It is the simplest form in which a matrix can be expressed. Irreducible representation.
Matrix Decomposition (+list): It is the simplest representation of the information contained in a matrix.
-Eigendecomposition
-Characteristic polynomial
-Determinant
-Cholesky decomposition
-QR decomposition
-Single Value decomposition (SVD)
Change of basis: Is when the elements of a matrix are expressed in terms of a different basis set than the original (they are linearly dependent).
Eigendecomposition: Is when a matrix is expressed as a canonical matrix. The values in the daigonal are called eigenvalues.
Principal component analysis (PCA): Eigendecompositition of the covariance matrix
Single Value Decomposition (SVD): Is the Eigenvalue deocomposition of a square matrix
Characteristic equation: det(M-xI)=0 when solved the results are the eigenvalues x of matrix M
Characteristic polynomial: Is the polynomial that contains the eigenvalues as roots and is invariant under matrix similarity.
Encoder & Decoder: Is a matrix that converts the standard matrix into eigenbasis and the decoder is the one that returns the matrix to its standard form.
Joint probability distribution function: Is the distribution that shows the dependance of the probability of one variable gives another.
Conditional Probability Distribution Function: Is a slice of the Joint probability distribution function, that shows the probability of an event, given that another has a specific value.
Marginal Distribution: Is the probability distribution of te variables contained in a subset w/o any constrain of the other variables
Mutual information: Is the measure of dependence between two variables (intersection of information/ correlation).
Covariance vs Correlation: Covaraiance looks at the difference between data sets whereas correlation at how dependent is one with respect to another.
Feature Vectors: Are the ones that reduce the dimensionality into vector that capture the variance in the data
Matrix Rank: Is the number of linearly independent vectors in the basis
Frobenius Norm: is the matrix norm defined as the square root of the sum of the absolute squares of its elements.
Low rank approximation: (Compression of data) Is the minimization of a matrix to another of lower rank that contains as much information from the progenitor as posible.
